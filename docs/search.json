[
  {
    "objectID": "listing.html",
    "href": "listing.html",
    "title": "Listing Example",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nSep 28, 2022\n\n\nSOMA Data Lakehouse\n\n\n\n\n\n\nSep 28, 2022\n\n\nOther Content\n\n\n\n\n\n\nSep 28, 2022\n\n\nAbout SOMA Data Lakehouse\n\n\n\n\n\n\nSep 27, 2022\n\n\nUsing SOMA Data Lakehouse\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SOMA Data Lakehouse",
    "section": "",
    "text": "This is a SOMA Data Lakehouse website.\nTo learn more about SOMA visit http://www.cepel.br/produtos/gestao-de-ativos__trashed/soma-2/.\nTo know about IoT and SOMA see this post"
  },
  {
    "objectID": "index.html#navigation-by-tags",
    "href": "index.html#navigation-by-tags",
    "title": "SOMA Data Lakehouse",
    "section": "Navigation By TAGS",
    "text": "Navigation By TAGS\nAmazing tags: #SOMA, #IoT, #ML, #AssetManagement"
  },
  {
    "objectID": "index.html#all-content-select-by-tag",
    "href": "index.html#all-content-select-by-tag",
    "title": "SOMA Data Lakehouse",
    "section": "All content select by TAG",
    "text": "All content select by TAG\n\n\nA comment in the margin with a bunch of text:\n\nThe Unified Modeling Language (UML) is a general-purpose, developmental modeling language in the field of software engineering that is intended to provide a standard way to visualize the design of a system.\n\nThe creation of UML was originally motivated by the desire to standardize the disparate notational systems and approaches to software design. It was developed at Rational Software in 1994–1995, with further development led by them through 1996.\n\nIn 1997, UML was adopted as a standard by the Object Management Group (OMG), and has been managed by this organization ever since. In 2005, UML was also published by the International Organization for Standardization (ISO) as an approved ISO standard. Since then the standard has been periodically revised to cover the latest revision of UML. In software engineering, most practitioners do not use UML, but instead produce informal hand drawn diagrams; these diagrams, however, often include elements from UML."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About SOMA Data Lakehouse",
    "section": "",
    "text": "bigdata analytics today"
  },
  {
    "objectID": "about.html#about-soma---asset-monitoring-oriented-system",
    "href": "about.html#about-soma---asset-monitoring-oriented-system",
    "title": "About SOMA Data Lakehouse",
    "section": "About SOMA - Asset Monitoring Oriented System",
    "text": "About SOMA - Asset Monitoring Oriented System\n\nIndustry 4.0 technologies applied to the diagnosis and prognosis of machines and equipments\nOne of the main challenges for companies in managing their assets is the translation of large masses of monitoring data into useful information for maintenance managers. The solution for this is the adoption of automated monitoring systems, which aim to provide reliable access to information on the status of monitored assets, support decision-making, bring efficiency gains and remove the risk of human error.\nAs a result of extensive experience in monitoring and evaluating assets in the electricity sector, SOMA implements and makes available, in the companies’ Web environment, a Maintenance 4.0 architecture. Applying Industry 4.0 concepts to Maintenance Engineering , SOMA adopts technologies that include Internet of Things, state-of-the-art cybersecurity, digital twins, AI, integration with other systems and cloud computing.\nSOMA is a flexible, robust and reliable system, focused on helping the management of physical assets, and which can be used to monitor various industrial processes. SOMA’s functionalities range from online monitoring of the equipment’s operating status by a maintenance technician to the diagnosis of its condition by a specialist engineer."
  },
  {
    "objectID": "using-dlh.html",
    "href": "using-dlh.html",
    "title": "Using SOMA Data Lakehouse",
    "section": "",
    "text": "To use SOMA Data Lakehouse you need some experience in at least one of the following programming languages:\n\nJava\nPython\nRust\nSQL"
  },
  {
    "objectID": "using-dlh.html#python-3-example",
    "href": "using-dlh.html#python-3-example",
    "title": "Using SOMA Data Lakehouse",
    "section": "Python 3 Example",
    "text": "Python 3 Example\nBelow is an illustrative example of how to use SQL with Arrow and Datafusion in Python language.\n!pip3 install jq pyarrow datafusion pandas matplotlib scipy\nRequirement already satisfied: jq in /usr/local/lib/python3.10/site-packages (1.3.0)\nRequirement already satisfied: pyarrow in /usr/local/lib/python3.10/site-packages (9.0.0)\nRequirement already satisfied: datafusion in /usr/local/lib/python3.10/site-packages (0.6.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/site-packages (1.5.0)\nRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/site-packages (from pyarrow) (1.23.3)\nRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/site-packages (from pandas) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas) (2022.2.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n\nCounting total rows of all SOMA Data Source measures in Data Lakehouse\n\n#!/usr/bin/env python3\n\nimport pyarrow as pa\nfrom datafusion import SessionContext\nctx = SessionContext()\n# There is a thousand parquet files in this directory\nd = '../data/reusable/'\nctx.register_parquet(\"soma\", d)\nsql_cmd = \"\"\"\n SELECT count(ts) as qty\n   FROM soma\n\"\"\"\nrb = ctx.sql(sql_cmd).collect()\nt1 = pa.Table.from_batches(rb)\nprint(\"Quantidade de registros no Dataset =\", t1[0][0])\n\nQuantidade de registros no Dataset = 11484000\n\n\n\n\nCounting rows grouping by UUID of SOMA Data Source\n\n#!/usr/bin/env python3\n\nimport pyarrow as pa\nfrom datafusion import SessionContext\nctx = SessionContext()\n# There is a bunch of parquet files in this directory\nd = '../data/reusable/'\nctx.register_parquet(\"soma\", d)\nsql_cmd = \"\"\"\n  SELECT dsuuid,  count(dsuuid) as qty\n    FROM soma\nGROUP BY dsuuid\n\"\"\"\nrb = ctx.sql(sql_cmd).collect()\nt1 = pa.Table.from_batches(rb)\ndf = t1.to_pandas()\nprint(df)\n\n                                             dsuuid     qty\n0   DataSource_609574d4-e153-445f-a37c-b893ecb0c5fd  396000\n1   DataSource_78686cdb-4144-4c6f-9e7e-66ba06871328  396000\n2   DataSource_cbe8a9af-2d93-47e6-88c9-7991f71168c2  396000\n3   DataSource_e0bdb337-49ae-468e-93b1-be1dd96baed3  396000\n4   DataSource_d85a1f65-57eb-4362-a791-ccff043acf43  396000\n5   DataSource_ac7c39d3-7bdd-4f2a-a075-5b24da3137e0  396000\n6   DataSource_dd860dd6-1450-46a8-8d9c-e9ab9b47f7e6  396000\n7   DataSource_18de68d3-e1d3-45d6-b3da-7a851067aeaa  396000\n8   DataSource_7cc50f92-9c10-4527-95ec-4b952718352b  792000\n9   DataSource_4c3fd574-3795-4af3-959f-d5e433065db7  396000\n10  DataSource_00f837fb-8c29-4123-ab02-51bb110f0f44  396000\n11  DataSource_270a0dd5-7868-4431-a29d-374a6f221693  396000\n12  DataSource_da2a80a7-a610-4a32-adae-6e829db2c889  792000\n13  DataSource_6233a59a-d614-4d1e-ab48-a0e8958523fc  396000\n14  DataSource_686af5de-ea63-4250-bcf5-1a5e791d3f1a  792000\n15  DataSource_d73fdb99-da74-4465-a56c-36d138a47382  792000\n16  DataSource_1d1adb59-f1d3-4e71-a0a4-cd124c0bea0b  396000\n17  DataSource_1116286a-d12a-4a0c-b421-c9b57dd7f008  792000\n18  DataSource_d3ab801b-ec8e-4208-952e-d92dc16627db  396000\n19  DataSource_e3590d55-c908-4734-abdb-d99c2c651e65  792000\n20  DataSource_1f313b4b-078f-42e3-a205-069b1a3ce3cc  396000\n21  DataSource_9bb6bdda-fb8c-4c02-88fc-fd73fda6f14a  792000\n\n\n\n\nRead a Parquet Dataset and display first five rows\n\n#!/usr/bin/env python3\n\nimport jq\nimport pandas as pd\nimport pyarrow as pa\nfrom datafusion import SessionContext\nctx = SessionContext()\n# There is a thousand parquet files in this directory\nd = '../data/reusable/'\nctx.register_parquet(\"soma\", d)\nsql_cmd = \"\"\"\n SELECT year, week, ts, dsuuid, value\n   FROM soma\n\"\"\"\nrb = ctx.sql(sql_cmd).collect()\nt1 = pa.Table.from_batches(rb)\ndf = t1.to_pandas()\nfirst_five = df.head()\nprint(df.describe())\nprint(first_five)\nt2 = pa.Table.from_pandas(first_five)\nprint(jq.compile('.').input(t2.to_pydict()).text())\n\n             year        week            ts         value\ncount  11484000.0  11484000.0  1.148400e+07  1.148400e+07\nmean       2019.0         9.0  1.551399e+15  2.641600e+00\nstd           0.0         0.0  4.328606e+08  2.887040e-01\nmin        2019.0         9.0  1.551398e+15  2.141600e+00\n25%        2019.0         9.0  1.551398e+15  2.391600e+00\n50%        2019.0         9.0  1.551399e+15  2.641600e+00\n75%        2019.0         9.0  1.551399e+15  2.891600e+00\nmax        2019.0         9.0  1.551400e+15  3.141600e+00\n   year  week                ts  \\\n0  2019     9  1551398459994001   \n1  2019     9  1551398459994455   \n2  2019     9  1551398459994910   \n3  2019     9  1551398459995364   \n4  2019     9  1551398459995819   \n\n                                            dsuuid   value  \n0  DataSource_4c3fd574-3795-4af3-959f-d5e433065db7  3.1416  \n1  DataSource_4c3fd574-3795-4af3-959f-d5e433065db7  3.1316  \n2  DataSource_4c3fd574-3795-4af3-959f-d5e433065db7  3.1216  \n3  DataSource_4c3fd574-3795-4af3-959f-d5e433065db7  3.1116  \n4  DataSource_4c3fd574-3795-4af3-959f-d5e433065db7  3.1016  \n{\"year\": [2019, 2019, 2019, 2019, 2019], \"week\": [9, 9, 9, 9, 9], \"ts\": [1551398459994001, 1551398459994455, 1551398459994910, 1551398459995364, 1551398459995819], \"dsuuid\": [\"DataSource_4c3fd574-3795-4af3-959f-d5e433065db7\", \"DataSource_4c3fd574-3795-4af3-959f-d5e433065db7\", \"DataSource_4c3fd574-3795-4af3-959f-d5e433065db7\", \"DataSource_4c3fd574-3795-4af3-959f-d5e433065db7\", \"DataSource_4c3fd574-3795-4af3-959f-d5e433065db7\"], \"value\": [3.1416, 3.1316, 3.1216000000000004, 3.1116000000000006, 3.101600000000001]}\n\n\n\n\nPlotting the time signal\n\n#!/usr/bin/env python3\n\nimport pandas as pd\nimport matplotlib\nimport pyarrow as pa\nfrom datafusion import SessionContext\ndash_line = \"-\" * 30\nctx = SessionContext()\n# There is a thousand parquet files in this directory\nd = '../data/reusable/60m/'\nctx.register_parquet(\"soma\", d)\nsql_cmd = \"\"\"\n  SELECT year, week, month, day, ts, dsuuid, value\n    FROM soma\n   WHERE ts > 0 -- 1663368556001001\n     AND dsuuid = 'DataSource_00f837fb-8c29-4123-ab02-51bb110f0f44'\nORDER BY ts\n   LIMIT 7000\n\"\"\"\nrb = ctx.sql(sql_cmd).collect()\nt1 = pa.Table.from_batches(rb)\ndf = t1.to_pandas()\ndf['date'] = pd.to_datetime(df['ts'] /1000000.0, unit='s')\nfirst_fifteen = df.head(15)\nlast_fifteen = df.tail(15)\nprint(dash_line, \"df.describe()\\n\", df.describe())\nprint(dash_line, \"first_fifteen\\n\", first_fifteen)\nprint(dash_line, \"last_fifteen\\n\", last_fifteen)\ndf.head(2200).plot(kind='scatter', x='ts', y='value')\n\n------------------------------ df.describe()\n          year    week   month     day            ts        value\ncount  7000.0  7000.0  7000.0  7000.0  7.000000e+03  7000.000000\nmean   2019.0     9.0     3.0     1.0  1.551398e+15     2.641600\nstd       0.0     0.0     0.0     0.0  9.184855e+05     0.288725\nmin    2019.0     9.0     3.0     1.0  1.551398e+15     2.141600\n25%    2019.0     9.0     3.0     1.0  1.551398e+15     2.391600\n50%    2019.0     9.0     3.0     1.0  1.551398e+15     2.641600\n75%    2019.0     9.0     3.0     1.0  1.551398e+15     2.891600\nmax    2019.0     9.0     3.0     1.0  1.551398e+15     3.141600\n------------------------------ first_fifteen\n     year  week  month  day                ts  \\\n0   2019     9      3    1  1551398400000001   \n1   2019     9      3    1  1551398400000455   \n2   2019     9      3    1  1551398400000910   \n3   2019     9      3    1  1551398400001364   \n4   2019     9      3    1  1551398400001819   \n5   2019     9      3    1  1551398400002273   \n6   2019     9      3    1  1551398400002728   \n7   2019     9      3    1  1551398400003182   \n8   2019     9      3    1  1551398400003637   \n9   2019     9      3    1  1551398400004091   \n10  2019     9      3    1  1551398400004546   \n11  2019     9      3    1  1551398400005000   \n12  2019     9      3    1  1551398400005455   \n13  2019     9      3    1  1551398400005909   \n14  2019     9      3    1  1551398400006364   \n\n                                             dsuuid   value  \\\n0   DataSource_00f837fb-8c29-4123-ab02-51bb110f0f44  3.1416   \n1   DataSource_00f837fb-8c29-4123-ab02-51bb110f0f44  3.1316   \n2   DataSource_00f837fb-8c29-4123-ab02-51bb110f0f44  3.1216   \n3   DataSource_00f837fb-8c29-4123-ab02-51bb110f0f44  3.1116   \n4   DataSource_00f837fb-8c29-4123-ab02-51bb110f0f44  3.1016   \n5   DataSource_00f837fb-8c29-4123-ab02-51bb110f0f44  3.0916   \n6   DataSource_00f837fb-8c29-4123-ab02-51bb110f0f44  3.0816   \n7   DataSource_00f837fb-8c29-4123-ab02-51bb110f0f44  3.0716   \n8   DataSource_00f837fb-8c29-4123-ab02-51bb110f0f44  3.0616   \n9   DataSource_00f837fb-8c29-4123-ab02-51bb110f0f44  3.0516   \n10  DataSource_00f837fb-8c29-4123-ab02-51bb110f0f44  3.0416   \n11  DataSource_00f837fb-8c29-4123-ab02-51bb110f0f44  3.0316   \n12  DataSource_00f837fb-8c29-4123-ab02-51bb110f0f44  3.0216   \n13  DataSource_00f837fb-8c29-4123-ab02-51bb110f0f44  3.0116   \n14  DataSource_00f837fb-8c29-4123-ab02-51bb110f0f44  3.0016   \n\n                            date  \n0  2019-03-01 00:00:00.000001024  \n1  2019-03-01 00:00:00.000454912  \n2  2019-03-01 00:00:00.000910080  \n3  2019-03-01 00:00:00.001363968  \n4  2019-03-01 00:00:00.001818880  \n5  2019-03-01 00:00:00.002273024  \n6  2019-03-01 00:00:00.002727936  \n7  2019-03-01 00:00:00.003181824  \n8  2019-03-01 00:00:00.003636992  \n9  2019-03-01 00:00:00.004091136  \n10 2019-03-01 00:00:00.004546048  \n11 2019-03-01 00:00:00.005000192  \n12 2019-03-01 00:00:00.005455104  \n13 2019-03-01 00:00:00.005908992  \n14 2019-03-01 00:00:00.006364160  \n------------------------------ last_fifteen\n       year  week  month  day                ts  \\\n6985  2019     9      3    1  1551398403174683   \n6986  2019     9      3    1  1551398403175138   \n6987  2019     9      3    1  1551398403175592   \n6988  2019     9      3    1  1551398403176047   \n6989  2019     9      3    1  1551398403176501   \n6990  2019     9      3    1  1551398403176956   \n6991  2019     9      3    1  1551398403177410   \n6992  2019     9      3    1  1551398403177865   \n6993  2019     9      3    1  1551398403178319   \n6994  2019     9      3    1  1551398403178774   \n6995  2019     9      3    1  1551398403179228   \n6996  2019     9      3    1  1551398403179683   \n6997  2019     9      3    1  1551398403180137   \n6998  2019     9      3    1  1551398403180592   \n6999  2019     9      3    1  1551398403181046   \n\n                                               dsuuid   value  \\\n6985  DataSource_00f837fb-8c29-4123-ab02-51bb110f0f44  2.9916   \n6986  DataSource_00f837fb-8c29-4123-ab02-51bb110f0f44  3.0016   \n6987  DataSource_00f837fb-8c29-4123-ab02-51bb110f0f44  3.0116   \n6988  DataSource_00f837fb-8c29-4123-ab02-51bb110f0f44  3.0216   \n6989  DataSource_00f837fb-8c29-4123-ab02-51bb110f0f44  3.0316   \n6990  DataSource_00f837fb-8c29-4123-ab02-51bb110f0f44  3.0416   \n6991  DataSource_00f837fb-8c29-4123-ab02-51bb110f0f44  3.0516   \n6992  DataSource_00f837fb-8c29-4123-ab02-51bb110f0f44  3.0616   \n6993  DataSource_00f837fb-8c29-4123-ab02-51bb110f0f44  3.0716   \n6994  DataSource_00f837fb-8c29-4123-ab02-51bb110f0f44  3.0816   \n6995  DataSource_00f837fb-8c29-4123-ab02-51bb110f0f44  3.0916   \n6996  DataSource_00f837fb-8c29-4123-ab02-51bb110f0f44  3.1016   \n6997  DataSource_00f837fb-8c29-4123-ab02-51bb110f0f44  3.1116   \n6998  DataSource_00f837fb-8c29-4123-ab02-51bb110f0f44  3.1216   \n6999  DataSource_00f837fb-8c29-4123-ab02-51bb110f0f44  3.1316   \n\n                              date  \n6985 2019-03-01 00:00:03.174683136  \n6986 2019-03-01 00:00:03.175138048  \n6987 2019-03-01 00:00:03.175591936  \n6988 2019-03-01 00:00:03.176047104  \n6989 2019-03-01 00:00:03.176500992  \n6990 2019-03-01 00:00:03.176955904  \n6991 2019-03-01 00:00:03.177409792  \n6992 2019-03-01 00:00:03.177864960  \n6993 2019-03-01 00:00:03.178319104  \n6994 2019-03-01 00:00:03.178774016  \n6995 2019-03-01 00:00:03.179228160  \n6996 2019-03-01 00:00:03.179683072  \n6997 2019-03-01 00:00:03.180136960  \n6998 2019-03-01 00:00:03.180592128  \n6999 2019-03-01 00:00:03.181046016  \n\n\n<AxesSubplot: xlabel='ts', ylabel='value'>\n\n\n\n\n\n\n\nComposite sinusoidal signal generation and frequency spectrum\nStarting with a simple example to familiarize ourselves with the digital signal processing API available in the SciPy library\n\n#!/usr/bin/env python3\n\nimport datetime\nimport numpy as np\nimport scipy as sp\nimport scipy.fftpack as fftpack\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfs = 22000 # sample frequency\ntstep = 1 / fs # time interval\nf0 = 100 # signal freq\nN = int(3 * fs / f0) # number off samples\n# time steps\nt = np.linspace(0, (N - 1) * tstep, N) # time steps\nfstep = fs / N # frequency interval\nf = np.linspace(0, (N - 1) * fstep, N) # frequency interval\ny1 = 1 * np.sin(2 * np.pi * f0 * t)\ny2 = 2 * np.sin(17 * np.pi * f0 * t)\ny = y1 + y2\n# plot\nfig, ax = plt.subplots(nrows=1, ncols=1)\nax.plot(t, y)\nplt.show()\n# FFT ---------------------------------\n# perform fft\nX = np.fft.fft(y)\nX_mag = np.abs(X) / N\n\nf_plot = f[0:int(N/2 + 1)]\nX_mag_plot = 2 * X_mag[0:int(N/2 +1)] \nX_mag_plot[0] = X_mag_plot[0] / 2\n\n# plot\nfig, [ax1, ax2] = plt.subplots(nrows=2, ncols=1)\nax1.plot(t, y, '-')\nax2.plot(f_plot, X_mag_plot, '-')\nplt.show()\nprint(\"arrays shapes: t and f_plot \")\nprint(t.shape, f_plot.shape)\n\n\n\n\n\n\n\narrays shapes: t and f_plot \n(660,) (331,)\n\n\n\n\nFrequency spectrum using FFT\n\n#!/usr/bin/env python3\n\nimport datetime\nimport numpy as np\nimport scipy as sp\nimport scipy.fftpack as fftpack\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport pyarrow as pa\nfrom datafusion import SessionContext\n# plt.style.use('seaborn-poster')\ndash_line = \"-\" * 30\nctx = SessionContext()\n# There is a thousand parquet files in this directory\nd = '../data/reusable/60m/'\nctx.register_parquet(\"soma\", d)\nsql_cmd = \"\"\"\n  SELECT year, week, month, day, ts, value\n    FROM soma\n   WHERE ts > 0 -- 1663368556001001\n     AND dsuuid = 'DataSource_00f837fb-8c29-4123-ab02-51bb110f0f44'\nORDER BY ts\n   LIMIT 2200\n\"\"\"\nrb = ctx.sql(sql_cmd).collect()\nt1 = pa.Table.from_batches(rb)\ndf = t1.to_pandas()\ndf.rename(columns = {'ts':'time'}, inplace = True)\ndf1 = df[['time', 'value']]\ndf1.time = df1.time - 1551398400000001\nprint(dash_line, \"df1.head\", df1.head)\n# -----------------------------------------\nv = df1['value'].to_numpy()\nprint(dash_line, \"\\n\\nvalues numpy Array:\", v)\nfft = fftpack.fft(v) # Complex Number array\namplitude = np.abs(fft)\nprint(dash_line, \"\\n\\namplitude = \", amplitude)\namp_power = amplitude ** 2\nangle = np.angle(fft)\nsample_freq = fftpack.fftfreq(v.size, 4545.45454545)\n# print(dash_line, \"\\n\\nsample_freq = \", sample_freq)\namp_freq = np.array([amplitude, sample_freq])\nprint(dash_line, \"\\n\\namp_freq = \", amp_freq)\n# -----------------------------------------\namp_position = amp_freq[0,:].argmax()\npeak_freq = amp_freq[1, amp_position]\nprint(dash_line, \"\\n\\namp_position =\", amp_position, \"peak_freq =\", peak_freq)\n\nhigh_freq_fft = fft.copy()\nhigh_freq_fft[np.abs(sample_freq) > peak_freq]\nfiltered = fftpack.ifft(high_freq_fft)\nprint(dash_line, \"filtered =\", filtered)\n\ndf2 = pd.DataFrame({'amplitude':amp_freq[0], 'frequency':amp_freq[1]})\ndf2 = df2.loc[(df2['frequency'] > 0)]\ndf2.head(256).plot(kind='line', x='frequency', y='amplitude')\nprint(\"\\n\\ndf2.describe\", df2.describe)\n\n------------------------------ df1.head <bound method NDFrame.head of         time   value\n0          0  3.1416\n1        454  3.1316\n2        909  3.1216\n3       1363  3.1116\n4       1818  3.1016\n...      ...     ...\n2195  997627  3.0916\n2196  998082  3.1016\n2197  998536  3.1116\n2198  998991  3.1216\n2199  999445  3.1316\n\n[2200 rows x 2 columns]>\n------------------------------ \n\nvalues numpy Array: [3.1416 3.1316 3.1216 ... 3.1116 3.1216 3.1316]\n------------------------------ \n\namplitude =  [5.81152000e+03 1.15389995e-13 1.13453368e-13 ... 1.09621129e-13\n 1.13453368e-13 1.15389995e-13]\n------------------------------ \n\namp_freq =  [[ 5.81152000e+03  1.15389995e-13  1.13453368e-13 ...  1.09621129e-13\n   1.13453368e-13  1.15389995e-13]\n [ 0.00000000e+00  1.00000000e-07  2.00000000e-07 ... -3.00000000e-07\n  -2.00000000e-07 -1.00000000e-07]]\n------------------------------ \n\namp_position = 0 peak_freq = 0.0\n------------------------------ filtered = [3.1416+2.86858511e-33j 3.1316-2.28605014e-17j 3.1216-4.84460956e-18j ...\n 3.1116-1.15533942e-17j 3.1216+1.14023661e-17j 3.1316-2.54910539e-17j]\n\n\ndf2.describe <bound method NDFrame.describe of          amplitude     frequency\n1     1.153900e-13  1.000000e-07\n2     1.134534e-13  2.000000e-07\n3     1.096211e-13  3.000000e-07\n4     9.532185e-14  4.000000e-07\n5     8.093728e-14  5.000000e-07\n...            ...           ...\n1095  6.890090e-16  1.095000e-04\n1096  1.000172e-15  1.096000e-04\n1097  2.830904e-15  1.097000e-04\n1098  4.944441e-15  1.098000e-04\n1099  3.574300e-15  1.099000e-04\n\n[1099 rows x 2 columns]>\n\n\n/var/folders/vt/h13jrd7j6p5537xcqs62q6100000gn/T/ipykernel_52070/610960007.py:30: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df1.time = df1.time - 1551398400000001"
  },
  {
    "objectID": "other.html",
    "href": "other.html",
    "title": "Other Content",
    "section": "",
    "text": "This is a Test 01"
  },
  {
    "objectID": "other.html#test-02",
    "href": "other.html#test-02",
    "title": "Other Content",
    "section": "Test 02",
    "text": "Test 02\nThis is a Test 02"
  }
]